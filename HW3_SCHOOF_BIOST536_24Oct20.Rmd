---
title: "BIOST 536 HW3"
author: "John Schoof"
date: "10/21/2020"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE)
knitr::opts_knit$set(root.dir = ("C:/Users/jscho/OneDrive - UW/FALL 2020-LAPTOP-7K6NFTGB/BIOST 536/HW/")) 

# clean data environment
rm(list=ls())

# load packages
library(haven)
library(tidyverse)
library(sandwich)
library(foreign)
library(survey)
library(stringr)

options(digits = 3) ## Formats output to 3 digits
set.seed(1) # set seed for any randomization that may follow
```


```{r question 4, }

## Create data frame
  
  data <- data.frame(
            x = c((rep(0, each=30)),(rep(1, each=30)),(rep(2, each=30))), 
            d = c((rep(0, each=20)),(rep(1, each=10)),
                  (rep(0, each=15)),(rep(1, each=15)),
                  (rep(0, each=10)),(rep(1, each=20))))

  table(data$x, data$d)

```



```{r question 4b, }

## Fit logistic regression model
  mod4 <- glm(d~x, family = "binomial", data=data)

  summary(mod4)
  
  ## coefficients and p = odds/1 + odds
    
    coef <- summary(mod4)$coefficients
  
    normal_se4 <- coef[, 2]
    rob_se4 <- sqrt(diag(vcovHC(mod4, type = "HC0")))
    normal_se4
    rob_se4
  
  # 95% CI
    conf_int4 <- coef[2,1] + 
    c(0, qnorm(c(0.025, 0.975))) * rob_se4[2]
    conf_int4
    exp(conf_int4)
  
  # odds and prob where x = 
    # x=0
      (x0 <- exp(coef[1,1]))
      (p0 <- x0/(1+x0))
    
    # x=1
      (x1 <- exp(coef[2,1]+coef[1,1]))
      (p1 <- x1/(1+x1))
    
    # x=2
      (x2 <- exp((2*coef[2,1])+coef[1,1]))
      (p2 <- x2/(1+x2))
  
```

$$
  \text{Logit (P}[D = 1 | X = x ]) = `r coef[1,1]` + `r coef[2,1]` * x
$$

C. According to the fitted model, what is the probability of D for individuals with X=0?  Why does this make sense?

$\text{Logit (P}[D = 1 | X = 0 ]) = \beta_0 + \beta_1 * 0$

$log(odds) = `r coef[1,1]` + `r coef[2,1]` * 0 = `r coef[1,1]`$

$odds = e^{`r coef[1,1]`} = `r x0`$

$probability = odds/(1+odds) = `r x0`/(1+`r x0`) = `r p0`$

The probability of D for individuals with X=0 is 0.333.  This makes sense because we see in our 2x3 table that 10 out of 30 people in the X=1 group are diseased.  Therefore the probability is also 0.333 if calculated using our table.  The exact same as with using our logistic regression model.  

D. According to the fitted model, what is the probability of D for individuals with X=1?  Why does this make sense?

$\text{Logit (P}[D = 1 | X = 1 ]) = \beta_0 + \beta_1 * 1$

$log(odds) = `r coef[1,1]` + `r coef[2,1]` * 1 = `r coef[1,1]` + `r coef[2,1]`$

$odds = e^{`r coef[1,1]`+`r coef[2,1]`} = `r x1`$

$probability = odds/(1+odds) = `r x1`/(1+`r x1`) = `r p1`$

The probability of D for individuals with X=1 is 0.5.  This makes sense because we see in our 2x3 table that 15 out of 30 people in the X=1 group are diseased.  Therefore the probability is also 0.5 if calculated using our table.  The exact same as with using our logistic regression model. 

E. According to the fitted model, what is the probability of D for individuals with X=2?  Why does this make sense?

$\text{Logit (P}[D = 1 | X = 2 ]) = \beta_0 + \beta_1 * 2$

$log(odds) = `r coef[1,1]` + `r coef[2,1]` * 2 = `r coef[1,1]` + `r coef[2,1] * 2`$

$odds = e^{`r coef[1,1]` + `r coef[2,1] * 2`} = `r x2`$

$probability = odds/(1+odds) = `r x2`/(1+`r x2`) = `r p2`$

The probability of D for individuals with X=2 is 0.666.  This makes sense because we see in our 2x3 table that 20 out of 30 people in the X=1 group are diseased.  Therefore the probability is also 0.666 if calculated using our table.  The exact same as with using our logistic regression model. 

```{r 4g plot, }

  data$logit.p[data$x==0] <- -0.693
  data$logit.p[data$x==1] <- 0
  data$logit.p[data$x==2] <- 0.693
  
  ggplot(data = data, mapping = aes(x=x, y=as.numeric(logit.p))) +
      geom_point() +
      labs(x = "X",
           y = "Logit(p)")

```

```{r question 5, }

## Create data frame
  
  data5 <- data.frame(
            x = c((rep(0, each=300)),(rep(1, each=300)),(rep(2, each=300))), 
            d = c((rep(0, each=200)),(rep(1, each=100)),
                  (rep(0, each=150)),(rep(1, each=150)),
                  (rep(0, each=100)),(rep(1, each=200))))

  table(data$x, data$d)

```

```{r }
## Fit logistic regression model
  mod5 <- glm(d~x, family = "binomial", data=data5)

  summary(mod5)
  
## coefficients and p = odds/1 + odds
  
  coef <- summary(mod5)$coefficients
  
# Robust SEs
  normal_se <- coef[, 2]
  rob_se <- sqrt(diag(vcovHC(mod5, type = "HC0")))
  normal_se
  rob_se

# 95% CI
  conf_int <- coef[2,1] + 
  c(0, qnorm(c(0.025, 0.975))) * rob_se[2]
  conf_int
  exp(conf_int)

```

Fit a simple logistic model to these data.  Compare and contrast the results with your results from Q4.  Your comparison should include regression parameter estimates, standard errors, and confidence intervals.

$$
  \text{Logit (P}[D = 1 | X = x ]) = `r coef[1,1]` + `r coef[2,1]` * x
$$
The Q5 unadjusted logistic regression model that fit is shown above.  Note that the point estimates for the coefficients are exactly the same as in the Q4 model.  The standard errors, confidence intervals, and p values differ in the two models.  In the Q5 model, $\beta_1$ is `r coef[2,1]` with a 95% confidence interval (calculated using robust stadard errors) of `r conf_int[1]`-`r conf_int[2] `, and our $\beta_1$ in the Q4 model has a 95% confidence interval of `r conf_int4[1]`-`r conf_int4[2] `.  The Q5 model has much smaller standard errors, resulitng in the narrower confidence intervals that were just mentioned.  The p value for the $\beta_1$ estimate in the Q5 model is also much smaller than that of the Q4 model.  The p value for $\beta_1$ in the Q4 model is 0.011 compared to $1.2*10^{15}$.  

```{r question 6, }

## Create data frame
  
  data6 <- data.frame(
            x = c((rep(-1, each=30)),(rep(0, each=30)),
                  (rep(1, each=30)),(rep(2, each=30)),
                  (rep(3, each=30))), 
            d = c((rep(0, each=30)),
                  (rep(0, each=20)),(rep(1, each=10)),
                  (rep(0, each=15)),(rep(1, each=15)),
                  (rep(0, each=10)),(rep(1, each=20)),
                                    (rep(1, each=30))))

  table(data6$x, data6$d)

```

```{r }
## Fit logistic regression model
  mod6 <- glm(d~x, family = "binomial", data=data6)

  summary(mod6)
  
## coefficients and p = odds/1 + odds
  
  coef6 <- summary(mod6)$coefficients
  
# Robust SEs
  normal_se6 <- coef6[, 2]
  rob_se6 <- sqrt(diag(vcovHC(mod6, type = "HC0")))
  normal_se6
  rob_se6

# 95% CI
  conf_int6 <- coef6[2,1] + 
  c(0, qnorm(c(0.025, 0.975))) * rob_se[2]
  conf_int6
  exp(conf_int6)
  
  
  # odds and prob where x = 
    # x=0
      (x0m6 <- exp(coef6[1,1]))
      (p0m6 <- x0m6/(1+x0m6))
    
    # x=1
      (x1m6 <- exp(coef6[2,1]+coef6[1,1]))
      (p1m6 <- x1m6/(1+x1m6))
    
    # x=2
      (x2m6 <- exp((2*coef6[2,1])+coef6[1,1]))
      (p2m6 <- x2m6/(1+x2m6))

```

$$
  \text{Logit (P}[D = 1 | X = x ]) = `r coef6[1,1]` + `r coef6[2,1]` * x
$$

C.  According to the fitted model, what is the probability of D for individuals with X=0?  Why is this different from Q3C?

$\text{Logit (P}[D = 1 | X = 0 ]) = \beta_0 + \beta_1 * 0$

$log(odds) = `r coef6[1,1]` + `r coef6[2,1]` * 0 = `r coef6[1,1]`$

$odds = e^{`r coef6[1,1]`} = `r x0m6`$

$probability = odds/(1+odds) = `r x0m6`/(1+`r x0m6`) = `r p0m6`$

D.  According to the fitted model, what is the probability of D for individuals with X=1?  How does this compare with Q3D?  Why does this make sense?

$\text{Logit (P}[D = 1 | X = 1 ]) = \beta_0 + \beta_1 * 1$

$log(odds) = `r coef6[1,1]` + `r coef6[2,1]` * 1 = `r coef6[1,1]` + `r coef6[2,1]`$

$odds = e^{`r coef6[1,1]`+`r coef6[2,1]`} = `r x1m6`$

$probability = odds/(1+odds) = `r x1m6`/(1+`r x1m6`) = `r p1m6`$




















